{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-23T13:16:24.505371Z",
     "start_time": "2025-10-23T13:16:21.612297Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:16:22.153907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761225382.174107   58320 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761225382.180605   58320 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761225382.197075   58320 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761225382.197092   58320 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761225382.197094   58320 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761225382.197095   58320 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-23 13:16:22.202412: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:16:32.867466Z",
     "start_time": "2025-10-23T13:16:30.518943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Excel file\n",
    "df = pd.read_excel('/home/ubuntu/deep_learning_exam1/excel/training/train_test_cleaned.xlsx')\n",
    "\n",
    "# Calculate class distribution for entire dataset\n",
    "print(\"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION - ENTIRE DATASET\")\n",
    "print(\"=\"*60)\n",
    "class_dist_all = df['target'].value_counts().sort_index()\n",
    "print(class_dist_all)\n",
    "print(f\"\\nTotal images: {len(df)}\")\n",
    "\n",
    "# Calculate class distribution for training set only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION - TRAINING SET ONLY\")\n",
    "print(\"=\"*60)\n",
    "train_df = df[df['split'] == 'train']\n",
    "class_dist_train = train_df['target'].value_counts().sort_index()\n",
    "print(class_dist_train)\n",
    "print(f\"\\nTotal training images: {len(train_df)}\")\n",
    "\n",
    "# Calculate class distribution for test set only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION - TEST SET ONLY\")\n",
    "print(\"=\"*60)\n",
    "test_df = df[df['split'] == 'test']\n",
    "class_dist_test = test_df['target'].value_counts().sort_index()\n",
    "print(class_dist_test)\n",
    "print(f\"\\nTotal test images: {len(test_df)}\")\n",
    "\n",
    "# Create a summary DataFrame for better visualization\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "summary = pd.DataFrame({\n",
    "    'Class': class_dist_train.index,\n",
    "    'Training Count': class_dist_train.values,\n",
    "    'Test Count': class_dist_test.values,\n",
    "    'Total Count': class_dist_train.values + class_dist_test.values\n",
    "})\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "max_count = class_dist_train.max()\n",
    "min_count = class_dist_train.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "print(f\"\\nImbalance Ratio (max/min): {imbalance_ratio:.2f}:1\")\n",
    "print(f\"Most frequent class: {class_dist_train.idxmax()} ({max_count} images)\")\n",
    "print(f\"Least frequent class: {class_dist_train.idxmin()} ({min_count} images)\")\n"
   ],
   "id": "2d6addac3e53b2fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASS DISTRIBUTION - ENTIRE DATASET\n",
      "============================================================\n",
      "target\n",
      "class1        24\n",
      "class10      834\n",
      "class2      2619\n",
      "class3      4998\n",
      "class4      1372\n",
      "class5     12773\n",
      "class6        72\n",
      "class7      1347\n",
      "class8      5218\n",
      "class9      1047\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total images: 30304\n",
      "\n",
      "============================================================\n",
      "CLASS DISTRIBUTION - TRAINING SET ONLY\n",
      "============================================================\n",
      "target\n",
      "class1        22\n",
      "class10      732\n",
      "class2      2325\n",
      "class3      4437\n",
      "class4      1207\n",
      "class5     11354\n",
      "class6        63\n",
      "class7      1199\n",
      "class8      4666\n",
      "class9       935\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total training images: 26940\n",
      "\n",
      "============================================================\n",
      "CLASS DISTRIBUTION - TEST SET ONLY\n",
      "============================================================\n",
      "target\n",
      "class1        2\n",
      "class10     102\n",
      "class2      294\n",
      "class3      561\n",
      "class4      165\n",
      "class5     1419\n",
      "class6        9\n",
      "class7      148\n",
      "class8      552\n",
      "class9      112\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total test images: 3364\n",
      "\n",
      "============================================================\n",
      "SUMMARY TABLE\n",
      "============================================================\n",
      "  Class  Training Count  Test Count  Total Count\n",
      " class1              22           2           24\n",
      "class10             732         102          834\n",
      " class2            2325         294         2619\n",
      " class3            4437         561         4998\n",
      " class4            1207         165         1372\n",
      " class5           11354        1419        12773\n",
      " class6              63           9           72\n",
      " class7            1199         148         1347\n",
      " class8            4666         552         5218\n",
      " class9             935         112         1047\n",
      "\n",
      "Imbalance Ratio (max/min): 516.09:1\n",
      "Most frequent class: class5 (11354 images)\n",
      "Least frequent class: class1 (22 images)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:16:32.902242Z",
     "start_time": "2025-10-23T13:16:32.893640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(666)\n",
    "\n",
    "# Target count for each class\n",
    "\n",
    "\n",
    "# Filter only training data\n",
    "train_df = df[df['split'] == 'train'].copy()\n",
    "\n",
    "TARGET_COUNT = 8000\n",
    "\n",
    "# Paths - MODIFY THESE TO YOUR ACTUAL PATHS\n",
    "IMAGE_PATH = '/home/ubuntu/deep_learning_exam1/Data/'  # Source images directory\n",
    "OUTPUT_PATH = '/home/ubuntu/deep_learning_exam1/Full_Balanced_Data/'  # Output directory for balanced dataset\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ],
   "id": "4b87eedcebd39886",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:16:33.500605Z",
     "start_time": "2025-10-23T13:16:33.498176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")"
   ],
   "id": "e014d141bf0a5a3c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:50:51.934866Z",
     "start_time": "2025-10-23T13:16:35.684247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "balanced_data = []\n",
    "\n",
    "# Global counter for ALL augmented images across all classes\n",
    "global_aug_counter = 0\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"BALANCING DATASET TO {TARGET_COUNT} IMAGES PER CLASS WITH UNIQUE IDs\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Process each class\n",
    "for class_name in ['class1', 'class2', 'class3', 'class4', 'class5',\n",
    "                   'class6', 'class7', 'class8', 'class9', 'class10']:\n",
    "\n",
    "    # Get images for this class\n",
    "    class_images = train_df[train_df['target'] == class_name].copy()\n",
    "    current_count = len(class_images)\n",
    "\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    print(f\"  Current count: {current_count}\")\n",
    "\n",
    "    # Case 1: Class has MORE than target count - randomly sample\n",
    "    if current_count > TARGET_COUNT:\n",
    "        print(f\"  Action: Randomly selecting {TARGET_COUNT} images\")\n",
    "\n",
    "        # Randomly sample TARGET_COUNT images\n",
    "        selected_images = class_images.sample(n=TARGET_COUNT, random_state=666)\n",
    "\n",
    "        # Copy selected images to output directory\n",
    "        for idx, row in selected_images.iterrows():\n",
    "            image_id = row['id']\n",
    "            src_path = os.path.join(IMAGE_PATH, image_id)\n",
    "            dst_path = os.path.join(OUTPUT_PATH, image_id)\n",
    "\n",
    "            try:\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                balanced_data.append({\n",
    "                    'id': image_id,\n",
    "                    'target': class_name,\n",
    "                    'split': 'train',\n",
    "                    'method': 'original_sampled'\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"  Error copying {image_id}: {str(e)}\")\n",
    "\n",
    "        print(f\"  Selected: {len(selected_images)} images\")\n",
    "\n",
    "    # Case 2: Class has LESS than target count - use all originals + augment\n",
    "    else:\n",
    "        print(f\"  Action: Using all {current_count} originals + generating {TARGET_COUNT - current_count} augmented\")\n",
    "\n",
    "        # First, copy all original images\n",
    "        for idx, row in class_images.iterrows():\n",
    "            image_id = row['id']\n",
    "            src_path = os.path.join(IMAGE_PATH, image_id)\n",
    "            dst_path = os.path.join(OUTPUT_PATH, image_id)\n",
    "\n",
    "            try:\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                balanced_data.append({\n",
    "                    'id': image_id,\n",
    "                    'target': class_name,\n",
    "                    'split': 'train',\n",
    "                    'method': 'original'\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"  Error copying {image_id}: {str(e)}\")\n",
    "\n",
    "        # Calculate how many augmented images needed\n",
    "        augment_count = TARGET_COUNT - current_count\n",
    "        augmentations_per_image = int(np.ceil(augment_count / current_count))\n",
    "\n",
    "        print(f\"  Augmentations per original image: ~{augmentations_per_image}\")\n",
    "\n",
    "        # Generate augmented images\n",
    "        generated_count = 0\n",
    "\n",
    "        # Shuffle the class_images to vary which images get more augmentations\n",
    "        class_images_shuffled = class_images.sample(frac=1, random_state=999).reset_index(drop=True)\n",
    "\n",
    "        for idx, row in class_images_shuffled.iterrows():\n",
    "            if generated_count >= augment_count:\n",
    "                break\n",
    "\n",
    "            image_id = row['id']\n",
    "            image_path = os.path.join(IMAGE_PATH, image_id)\n",
    "\n",
    "            try:\n",
    "                # Load image\n",
    "                img = load_img(image_path)\n",
    "                x = img_to_array(img)\n",
    "                x = x.reshape((1,) + x.shape)\n",
    "\n",
    "                # Generate augmented images\n",
    "                aug_iter = datagen.flow(x, batch_size=1024, seed=None)  # Changed seed to None for more randomness\n",
    "\n",
    "                for i in range(augmentations_per_image):\n",
    "                    if generated_count >= augment_count:\n",
    "                        break\n",
    "\n",
    "                    # Generate augmented image\n",
    "                    aug_img = next(aug_iter)[0].astype('uint8')\n",
    "\n",
    "                    # Create UNIQUE filename with class name and GLOBAL counter\n",
    "                    # Format: classname_aug_globalcounter.jpg\n",
    "                    extension = '.jpg'\n",
    "                    new_image_id = f\"{class_name}_aug_{global_aug_counter:06d}{extension}\"\n",
    "                    new_image_path = os.path.join(OUTPUT_PATH, new_image_id)\n",
    "\n",
    "                    # Double check uniqueness - if file exists, increment counter\n",
    "                    while os.path.exists(new_image_path) or new_image_id in [d['id'] for d in balanced_data]:\n",
    "                        global_aug_counter += 1\n",
    "                        new_image_id = f\"{class_name}_aug_{global_aug_counter:06d}{extension}\"\n",
    "                        new_image_path = os.path.join(OUTPUT_PATH, new_image_id)\n",
    "\n",
    "                    # Save augmented image\n",
    "                    array_to_img(aug_img).save(new_image_path)\n",
    "\n",
    "                    # Store information\n",
    "                    balanced_data.append({\n",
    "                        'id': new_image_id,\n",
    "                        'target': class_name,\n",
    "                        'split': 'train',\n",
    "                        'method': 'augmented',\n",
    "                        'source_image': image_id\n",
    "                    })\n",
    "\n",
    "                    generated_count += 1\n",
    "                    global_aug_counter += 1  # Increment global counter for next augmented image\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {image_id}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"  Total images: {current_count} original + {generated_count} augmented = {current_count + generated_count}\")\n",
    "        print(f\"  Global augmented counter now at: {global_aug_counter}\")\n",
    "\n",
    "# Create DataFrame with balanced data\n",
    "balanced_df = pd.DataFrame(balanced_data)"
   ],
   "id": "320086509f262811",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BALANCING DATASET TO 8000 IMAGES PER CLASS WITH UNIQUE IDs\n",
      "======================================================================\n",
      "\n",
      "class1:\n",
      "  Current count: 22\n",
      "  Action: Using all 22 originals + generating 7978 augmented\n",
      "  Augmentations per original image: ~363\n",
      "  Total images: 22 original + 7978 augmented = 8000\n",
      "  Global augmented counter now at: 7978\n",
      "\n",
      "class2:\n",
      "  Current count: 2325\n",
      "  Action: Using all 2325 originals + generating 5675 augmented\n",
      "  Augmentations per original image: ~3\n",
      "  Total images: 2325 original + 5675 augmented = 8000\n",
      "  Global augmented counter now at: 13653\n",
      "\n",
      "class3:\n",
      "  Current count: 4437\n",
      "  Action: Using all 4437 originals + generating 3563 augmented\n",
      "  Augmentations per original image: ~1\n",
      "  Total images: 4437 original + 3563 augmented = 8000\n",
      "  Global augmented counter now at: 17216\n",
      "\n",
      "class4:\n",
      "  Current count: 1207\n",
      "  Action: Using all 1207 originals + generating 6793 augmented\n",
      "  Augmentations per original image: ~6\n",
      "  Total images: 1207 original + 6793 augmented = 8000\n",
      "  Global augmented counter now at: 24009\n",
      "\n",
      "class5:\n",
      "  Current count: 11354\n",
      "  Action: Randomly selecting 8000 images\n",
      "  Selected: 8000 images\n",
      "\n",
      "class6:\n",
      "  Current count: 63\n",
      "  Action: Using all 63 originals + generating 7937 augmented\n",
      "  Augmentations per original image: ~126\n",
      "  Total images: 63 original + 7937 augmented = 8000\n",
      "  Global augmented counter now at: 31946\n",
      "\n",
      "class7:\n",
      "  Current count: 1199\n",
      "  Action: Using all 1199 originals + generating 6801 augmented\n",
      "  Augmentations per original image: ~6\n",
      "  Total images: 1199 original + 6801 augmented = 8000\n",
      "  Global augmented counter now at: 38747\n",
      "\n",
      "class8:\n",
      "  Current count: 4666\n",
      "  Action: Using all 4666 originals + generating 3334 augmented\n",
      "  Augmentations per original image: ~1\n",
      "  Total images: 4666 original + 3334 augmented = 8000\n",
      "  Global augmented counter now at: 42081\n",
      "\n",
      "class9:\n",
      "  Current count: 935\n",
      "  Action: Using all 935 originals + generating 7065 augmented\n",
      "  Augmentations per original image: ~8\n",
      "  Total images: 935 original + 7065 augmented = 8000\n",
      "  Global augmented counter now at: 49146\n",
      "\n",
      "class10:\n",
      "  Current count: 732\n",
      "  Action: Using all 732 originals + generating 7268 augmented\n",
      "  Augmentations per original image: ~10\n",
      "  Total images: 732 original + 7268 augmented = 8000\n",
      "  Global augmented counter now at: 56414\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:50:52.080781Z",
     "start_time": "2025-10-23T13:50:52.051151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify uniqueness\n",
    "unique_ids = balanced_df['id'].nunique()\n",
    "total_ids = len(balanced_df)\n",
    "duplicates = balanced_df[balanced_df.duplicated(subset=['id'], keep=False)]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"UNIQUENESS CHECK\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total images: {total_ids}\")\n",
    "print(f\"Unique IDs: {unique_ids}\")\n",
    "if unique_ids == total_ids:\n",
    "    print(\"✓ SUCCESS: All IDs are unique!\")\n",
    "else:\n",
    "    print(f\"✗ WARNING: {total_ids - unique_ids} duplicate IDs found!\")\n",
    "    print(\"\\nDuplicate IDs:\")\n",
    "    print(duplicates[['id', 'target', 'method']].sort_values('id'))\n"
   ],
   "id": "3020e1d5209e5a03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UNIQUENESS CHECK\n",
      "======================================================================\n",
      "Total images: 80000\n",
      "Unique IDs: 80000\n",
      "✓ SUCCESS: All IDs are unique!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:50:52.392756Z",
     "start_time": "2025-10-23T13:50:52.124279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify class distribution\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL BALANCED CLASS DISTRIBUTION\")\n",
    "print(\"=\"*70)\n",
    "for class_name in train_df['target'].unique():\n",
    "    count = len(balanced_df[balanced_df['target'] == class_name])\n",
    "    original_count = len(balanced_df[(balanced_df['target'] == class_name) &\n",
    "                                     (balanced_df['method'].isin(['original', 'original_sampled']))])\n",
    "    augmented_count = len(balanced_df[(balanced_df['target'] == class_name) &\n",
    "                                      (balanced_df['method'] == 'augmented')])\n",
    "    print(f\"{class_name}: {count} total (Original: {original_count}, Augmented: {augmented_count})\")\n",
    "\n",
    "balanced_df\n",
    "\n"
   ],
   "id": "bd4d7542a716f85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL BALANCED CLASS DISTRIBUTION\n",
      "======================================================================\n",
      "class4: 8000 total (Original: 1207, Augmented: 6793)\n",
      "class5: 8000 total (Original: 8000, Augmented: 0)\n",
      "class2: 8000 total (Original: 2325, Augmented: 5675)\n",
      "class8: 8000 total (Original: 4666, Augmented: 3334)\n",
      "class9: 8000 total (Original: 935, Augmented: 7065)\n",
      "class10: 8000 total (Original: 732, Augmented: 7268)\n",
      "class3: 8000 total (Original: 4437, Augmented: 3563)\n",
      "class7: 8000 total (Original: 1199, Augmented: 6801)\n",
      "class6: 8000 total (Original: 63, Augmented: 7937)\n",
      "class1: 8000 total (Original: 22, Augmented: 7978)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                           id   target  split     method   source_image\n",
       "0               img_19717.jpg   class1  train   original            NaN\n",
       "1               img_29529.jpg   class1  train   original            NaN\n",
       "2               img_24038.jpg   class1  train   original            NaN\n",
       "3               img_13153.jpg   class1  train   original            NaN\n",
       "4               img_16478.jpg   class1  train   original            NaN\n",
       "...                       ...      ...    ...        ...            ...\n",
       "79995  class10_aug_056409.jpg  class10  train  augmented  img_15191.jpg\n",
       "79996  class10_aug_056410.jpg  class10  train  augmented  img_15191.jpg\n",
       "79997  class10_aug_056411.jpg  class10  train  augmented  img_15191.jpg\n",
       "79998  class10_aug_056412.jpg  class10  train  augmented  img_15191.jpg\n",
       "79999  class10_aug_056413.jpg  class10  train  augmented  img_15191.jpg\n",
       "\n",
       "[80000 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>split</th>\n",
       "      <th>method</th>\n",
       "      <th>source_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_19717.jpg</td>\n",
       "      <td>class1</td>\n",
       "      <td>train</td>\n",
       "      <td>original</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_29529.jpg</td>\n",
       "      <td>class1</td>\n",
       "      <td>train</td>\n",
       "      <td>original</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_24038.jpg</td>\n",
       "      <td>class1</td>\n",
       "      <td>train</td>\n",
       "      <td>original</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_13153.jpg</td>\n",
       "      <td>class1</td>\n",
       "      <td>train</td>\n",
       "      <td>original</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_16478.jpg</td>\n",
       "      <td>class1</td>\n",
       "      <td>train</td>\n",
       "      <td>original</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>class10_aug_056409.jpg</td>\n",
       "      <td>class10</td>\n",
       "      <td>train</td>\n",
       "      <td>augmented</td>\n",
       "      <td>img_15191.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>class10_aug_056410.jpg</td>\n",
       "      <td>class10</td>\n",
       "      <td>train</td>\n",
       "      <td>augmented</td>\n",
       "      <td>img_15191.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>class10_aug_056411.jpg</td>\n",
       "      <td>class10</td>\n",
       "      <td>train</td>\n",
       "      <td>augmented</td>\n",
       "      <td>img_15191.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>class10_aug_056412.jpg</td>\n",
       "      <td>class10</td>\n",
       "      <td>train</td>\n",
       "      <td>augmented</td>\n",
       "      <td>img_15191.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>class10_aug_056413.jpg</td>\n",
       "      <td>class10</td>\n",
       "      <td>train</td>\n",
       "      <td>augmented</td>\n",
       "      <td>img_15191.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:50:55.630642Z",
     "start_time": "2025-10-23T13:50:52.428090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = df[df['split'] == 'test'].copy()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COPYING TEST IMAGES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total test images to copy: {len(test_df)}\")\n",
    "\n",
    "# Copy test images and track them\n",
    "test_data = []\n",
    "copied_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    image_id = row['id']\n",
    "    src_path = os.path.join(IMAGE_PATH, image_id)\n",
    "    dst_path = os.path.join(OUTPUT_PATH, image_id)\n",
    "\n",
    "    try:\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "        # Store test image information\n",
    "        test_data.append({\n",
    "            'id': image_id,\n",
    "            'target': row['target'],\n",
    "            'split': 'test',\n",
    "            'method': 'original'\n",
    "        })\n",
    "        copied_count += 1\n",
    "\n",
    "        if copied_count % 500 == 0:\n",
    "            print(f\"  Copied {copied_count} images...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error copying {image_id}: {str(e)}\")\n",
    "        error_count += 1\n",
    "\n",
    "print(f\"\\nSuccessfully copied: {copied_count} test images\")\n",
    "print(f\"Errors: {error_count} images\")"
   ],
   "id": "56065f6c5453ad15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COPYING TEST IMAGES\n",
      "======================================================================\n",
      "Total test images to copy: 3364\n",
      "  Copied 500 images...\n",
      "  Copied 1000 images...\n",
      "  Copied 1500 images...\n",
      "  Copied 2000 images...\n",
      "  Copied 2500 images...\n",
      "  Copied 3000 images...\n",
      "\n",
      "Successfully copied: 3364 test images\n",
      "Errors: 0 images\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:51:05.437189Z",
     "start_time": "2025-10-23T13:50:55.809300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataFrame with test data\n",
    "test_data_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Combine balanced training data with test data\n",
    "combined_df = pd.concat([balanced_df, test_data_df], ignore_index=True)\n",
    "\n",
    "# Save the combined Excel file\n",
    "class_to_onehot = {\n",
    "    'class1': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'class2': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'class3': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'class4': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'class5': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    'class6': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    'class7': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    'class8': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    'class9': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    'class10': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "# Add the target_class column with one-hot encoded arrays\n",
    "combined_df['target_class'] = combined_df['target'].map(class_to_onehot)\n",
    "\n",
    "# Reorder columns to match the format: id, target, split, target_class, (other columns)\n",
    "# Get all column names\n",
    "all_columns = combined_df.columns.tolist()\n",
    "\n",
    "# Define desired column order\n",
    "desired_order = ['id', 'target', 'split', 'target_class']\n",
    "\n",
    "# Add any remaining columns that weren't in desired_order\n",
    "remaining_columns = [col for col in all_columns if col not in desired_order]\n",
    "final_column_order = desired_order + remaining_columns\n",
    "\n",
    "# Reorder the DataFrame\n",
    "combined_df = combined_df[final_column_order]\n",
    "\n",
    "# Save the updated Excel file\n",
    "combined_df.to_excel('/home/ubuntu/deep_learning_exam1/excel/training/train_test_balanced_full.xlsx', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training images: {len(balanced_df)}\")\n",
    "print(f\"Test images: {len(test_data_df)}\")\n",
    "print(f\"Total images: {len(combined_df)}\")\n",
    "\n",
    "# Show split distribution\n",
    "print(\"\\nSplit Distribution:\")\n",
    "print(combined_df['split'].value_counts())\n",
    "\n",
    "# Show class distribution for test set\n",
    "print(\"\\nTest Set Class Distribution:\")\n",
    "test_class_dist = test_data_df['target'].value_counts().sort_index()\n",
    "for class_name, count in test_class_dist.items():\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "print(f\"\\nAll images saved to: {OUTPUT_PATH}\")\n",
    "print(f\"Complete metadata saved to: train_test_balanced.xlsx\")\n",
    "print(\"=\"*70)"
   ],
   "id": "f3268149caadbe29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY\n",
      "======================================================================\n",
      "Training images: 80000\n",
      "Test images: 3364\n",
      "Total images: 83364\n",
      "\n",
      "Split Distribution:\n",
      "split\n",
      "train    80000\n",
      "test      3364\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Set Class Distribution:\n",
      "  class1: 2\n",
      "  class10: 102\n",
      "  class2: 294\n",
      "  class3: 561\n",
      "  class4: 165\n",
      "  class5: 1419\n",
      "  class6: 9\n",
      "  class7: 148\n",
      "  class8: 552\n",
      "  class9: 112\n",
      "\n",
      "All images saved to: /home/ubuntu/deep_learning_exam1/Full_Balanced_Data/\n",
      "Complete metadata saved to: train_test_balanced.xlsx\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the balanced Excel file\n",
    "df_bal = pd.read_excel('/home/ubuntu/deep_learning_exam1/excel/training/train_test_balanced_full.xlsx')\n",
    "\n",
    "# Create a mapping from class names to one-hot encoded arrays\n",
    "# Classes are: class1, class2, class3, class4, class5, class6, class7, class8, class9, class10\n",
    "class_to_onehot = {\n",
    "    'class1': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'class2': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'class3': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'class4': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'class5': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    'class6': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    'class7': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    'class8': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    'class9': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    'class10': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "# Add the target_class column with one-hot encoded arrays\n",
    "df_bal['target_class'] = df_bal['target'].map(class_to_onehot)\n",
    "\n",
    "# Reorder columns to match the format: id, target, split, target_class, (other columns)\n",
    "# Get all column names\n",
    "all_columns = df_bal.columns.tolist()\n",
    "\n",
    "# Define desired column order\n",
    "desired_order = ['id', 'target', 'split', 'target_class']\n",
    "\n",
    "# Add any remaining columns that weren't in desired_order\n",
    "remaining_columns = [col for col in all_columns if col not in desired_order]\n",
    "final_column_order = desired_order + remaining_columns\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df_bal = df_bal[final_column_order]\n",
    "\n",
    "# Save the updated Excel file\n",
    "df_bal.to_excel('train_test_balanced_new.xlsx', index=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ONE-HOT ENCODING ADDED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nSample of the updated DataFrame:\")\n",
    "print(df_bal[['id', 'target', 'split', 'target_class']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total rows: {len(df_bal)}\")\n",
    "print(f\"Columns: {df_bal.columns.tolist()}\")\n",
    "\n",
    "# Verify one-hot encoding for each class\n",
    "print(\"\\nOne-hot encoding verification:\")\n",
    "for class_name in ['class1', 'class2', 'class3', 'class4', 'class5',\n",
    "                   'class6', 'class7', 'class8', 'class9', 'class10']:\n",
    "    sample = df_bal[df_bal['target'] == class_name]['target_class'].iloc[0]\n",
    "    print(f\"{class_name}: {sample}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Updated file saved as: train_test_balanced_new.xlsx\")\n",
    "print(\"=\"*70)\n"
   ],
   "id": "cbcefd94158e663a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a162453e4bad82b7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
